# Introduction
This repository comprises notebooks covering the primary code stacks and skills required to progress through deep learning material. The repository targets a graduate-level audience and focuses on deep learning concepts. It assumes you have been exposed to traditional machine learning concepts, like supervised, unsupervised, dimensional reduction, and linear algebra. It also assumes you grasp frameworks such as scikit-learn, pytorch, and tensorflow. These tutorials will be primarily written in JAX, to provide the most interpretable detail between mathematical proofs and code implementations.

# Notebook Outline
Review of the basics
 - Fundamental Concepts in Linear Algebra and Calculus
 - Backpropagation example w/ the Delta rule and LMS
 - Multi-layer perceptrons w/ JAX
 - Convolutional Neural Networks from Scratch w/ JAX
 - Transformers w/JAX
